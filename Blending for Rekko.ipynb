{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16073\n",
      "20853\n",
      "12935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "l = ['1.json',\n",
    "     '2.json',\n",
    "     '3.json']\n",
    "dicts = []\n",
    "for el in l:\n",
    "    with open(el, 'r') as f:\n",
    "        \n",
    "        dicts.append(json.load(f))\n",
    "        print(len(dicts[-1]))\n",
    "len(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49394"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = {}\n",
    "for el in dicts:\n",
    "    for k in el.keys():\n",
    "        ans[k] = el[k]\n",
    "# если длина меньше 49к, сабмитить нет смысла. НУжно делать предикт по всем    \n",
    "len(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('my_best.json', 'w') as f:\n",
    "    json.dump(ans, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объединение двух json'ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "d1 = {}\n",
    "d2 = {}\n",
    "with open('./share/2_5312170359494017878.json', 'r') as f:\n",
    "    d2 = json.load(f)\n",
    "    \n",
    "with open('./share/nn_light_bm.json', 'r') as f:\n",
    "    d1 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average intersaction equals 9.309129171259645,7.664415104970264\n"
     ]
    }
   ],
   "source": [
    "av = []\n",
    "d = {}\n",
    "counter = 0\n",
    "\n",
    "for key in d1.keys():\n",
    "    if key in d2.keys():\n",
    "        ar1 = np.array(d1[key])\n",
    "       # print(ar1)\n",
    "        ar2 = np.array(d2[key])\n",
    "        inter = np.intersect1d(ar1,ar2)\n",
    "        av.append(len(inter))\n",
    "        to_add = []\n",
    "        for el in ar2:\n",
    "            if el  in inter:\n",
    "                to_add.append(el)\n",
    "        for el in ar2:\n",
    "            if el  not in to_add:\n",
    "                to_add.append(el)\n",
    "        \n",
    "        \n",
    "        to_add = np.array(to_add)\n",
    "        \n",
    "        d[key] = list(map(int,list(to_add)))\n",
    "\n",
    "    else:\n",
    "        d[key] = d1[key]\n",
    "\n",
    "  \n",
    "\n",
    "#with open('1.json', 'w') as f:\n",
    "#    json.dump(d, f)\n",
    "    \n",
    "print('average intersaction equals {},{}'.format(np.array(av).mean(),np.array(av).var()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49895"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Женин метод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {}\n",
    "d2 = {}\n",
    "d3 = {}\n",
    "#with open('./share/predskazania_setki_all.json', 'r') as f:\n",
    "#    d2 = json.load(f)\n",
    "    \n",
    "with open('./share/light_fm_1604.json', 'r') as f:\n",
    "    d2 = json.load(f)\n",
    "    \n",
    "with open('./share/16_set_to_submit.json', 'r') as f:\n",
    "    d1 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = set(d1).union(set(d2))#.union(set(d3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'defauldict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-51d26c56611b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdefauldict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'defauldict'"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict,defauldict\n",
    "result = {}\n",
    "for user in new:\n",
    "    r1 = False\n",
    "    r2 = False\n",
    "    r3 = False\n",
    "    try:\n",
    "        ar1 = d1[user]\n",
    "        r1 = True\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        ar2 = d2[user]\n",
    "        r2 = True\n",
    "    except:\n",
    "        pass\n",
    "#    try:\n",
    "#        ar3 = d3[user]\n",
    "#        r3 = True\n",
    "#    except:\n",
    "#        pass\n",
    "    all_films = list(set(ar1).union(set(ar2)))#.union(set(ar3)))\n",
    "  #  print(all_films)\n",
    "    f_dict ={}\n",
    "    for el in all_films:\n",
    "        rank = 0\n",
    "        to_drop= 0\n",
    "        if el in ar1:\n",
    "            rank += ar1.index(el)\n",
    "        else:\n",
    "            rank +=21\n",
    "        if el in ar2:\n",
    "            rank += ar2.index(el)\n",
    "        else:\n",
    "            rank +=21\n",
    "    #    if el in ar3:\n",
    "    #        rank += ar3.index(el)\n",
    "    #    else:\n",
    "    #        rank +=21\n",
    "        f_dict[el] = rank\n",
    "        \n",
    "    t = sorted(f_dict.items(), key=lambda x: x[1])\n",
    "    to_add =[]\n",
    "    for el in t:\n",
    "        to_add.append(el[0])\n",
    "    result[user] = to_add[:20]\n",
    "   # print(result[user])\n",
    "        \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('blend.json', 'w') as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result[\"0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 55}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([1,2,3,4]).union([2,3,4,55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./share/bm25_last_submit.json', 'r') as f:\n",
    "    d2 = json.load(f)\n",
    "    \n",
    "with open('./share/blend.json', 'r') as f:\n",
    "    d1 = json.load(f)\n",
    "    \n",
    "with open('./share/answer_50.json', 'r') as f:\n",
    "    d4 = json.load(f)\n",
    "    \n",
    "with open('./share/rf.json', 'r') as f:\n",
    "    d5 = json.load(f)\n",
    "    \n",
    "    \n",
    "    \n",
    "with open('./share/2_5312170359494017878.json', 'r') as f:\n",
    "    d3 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_merged = dict()\n",
    "lens = []\n",
    "for user, els1 in d1.items():\n",
    "    merget_score = defaultdict(int)\n",
    "\n",
    "    els2 = d2[user]\n",
    "    els3 = d3[user]\n",
    "    els4 = d4[user]\n",
    "    els5 = d5[user]\n",
    "    union_el = set(els1).union(els2).union(els3).union(els4).union(els5)\n",
    "    for i, el2 in enumerate(els2):\n",
    "        merget_score[el2] += i- 1\n",
    "    for el in union_el.difference(els2):\n",
    "        merget_score[el] += 19\n",
    "        \n",
    "    for i, el3 in enumerate(els3):\n",
    "        merget_score[el3] += i\n",
    "    for el in union_el.difference(els3):\n",
    "        merget_score[el] += 20\n",
    "        \n",
    "    for i, el4 in enumerate(els4):\n",
    "        merget_score[el4] += i+1\n",
    "    for el in union_el.difference(els4):\n",
    "        merget_score[el] += 21\n",
    "        \n",
    "    for i, el5 in enumerate(els5):\n",
    "        merget_score[el5] += i+2\n",
    "    for el in union_el.difference(els5):\n",
    "        merget_score[el] += 22\n",
    "        \n",
    "        \n",
    "    current_top = list(zip(*sorted(merget_score.items(),key=lambda x:x[1])))[0]\n",
    "    lens.append(len(current_top))\n",
    "    sol_merged[user] = current_top[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./share/final.json', 'w') as f:\n",
    "    json.dump(sol_merged, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5814547965520875"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation(sol_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(dict_):\n",
    "    d1 = {}\n",
    "    with open('./share/2_5312170359494017878.json', 'r') as f:\n",
    "        d1 = json.load(f)\n",
    "    av = []\n",
    "\n",
    "\n",
    "    for key in d1.keys():\n",
    "        if key in dict_.keys():\n",
    "            ar1 = np.array(d1[str(key)])\n",
    "         # print(ar1)\n",
    "            ar2 = np.array(dict_[str(key)])\n",
    "            inter = np.intersect1d(ar1,ar2)\n",
    "        #  av.append(len(inter))\n",
    "            av.append(mapk([ar1],[ar2]))\n",
    "            to_add = []\n",
    "            for el in ar1:\n",
    "                if el  in inter:\n",
    "                    to_add.append(el)\n",
    "            for el in ar1:\n",
    "                if el  not in to_add:\n",
    "                    to_add.append(el)\n",
    "\n",
    "\n",
    "            to_add = np.array(to_add)\n",
    "    return np.mean(av)\n",
    "\n",
    "\n",
    "\n",
    "def mapk(actual, predicted, k=20):\n",
    "    \n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])\n",
    "  \n",
    "def apk(actual, predicted, k=10):\n",
    "\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "   # if not actual:\n",
    "   #     return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11192012412112942"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation(d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
