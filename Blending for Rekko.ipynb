{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blending for Rekko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы повысить скор, надо объединять результаты предсказаний от разных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 способ \"shuffle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот способ заключается в следующем. Берется два сабмита. Один сабмит хорошим скором от одной модели, и второй сабмит с чуть меньшим скором, но от другой модели. Далее для каждого пользователя находится пересечение фильмов. Те фильмы, в первом сабмите, которые есть во втором, остаются на своих местах. А вот фильмы, которые присутствуют только в первом, \"вылетают\" со своих мест и занимают оставшиеся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "d1 = {}\n",
    "d2 = {}\n",
    "with open('./share/2_5312170359494017878.json', 'r') as f:\n",
    "    d2 = json.load(f)\n",
    "    \n",
    "with open('./share/nn_light_bm.json', 'r') as f:\n",
    "    d1 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average intersaction equals 9.309129171259645,7.664415104970264\n"
     ]
    }
   ],
   "source": [
    "av = []\n",
    "d = {}\n",
    "counter = 0\n",
    "\n",
    "for key in d1.keys():\n",
    "    if key in d2.keys():\n",
    "        ar1 = np.array(d1[key])\n",
    "        ar2 = np.array(d2[key])\n",
    "        inter = np.intersect1d(ar1,ar2)\n",
    "        av.append(len(inter))\n",
    "        to_add = []\n",
    "        for el in ar2:\n",
    "            if el  in inter:\n",
    "                to_add.append(el)\n",
    "        for el in ar2:\n",
    "            if el  not in to_add:\n",
    "                to_add.append(el)\n",
    "        \n",
    "        \n",
    "        to_add = np.array(to_add)\n",
    "        \n",
    "        d[key] = list(map(int,list(to_add)))\n",
    "\n",
    "    else:\n",
    "        d[key] = d1[key]\n",
    "\n",
    "  \n",
    "\n",
    "with open('1.json', 'w') as f:\n",
    "    json.dump(d, f)\n",
    "    \n",
    "print('average intersaction equals {},{}'.format(np.array(av).mean(),np.array(av).var()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49895"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Второй метод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заключается в суммировании общего рейтинга и дальнейший сортировки по нему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./share/bm25_last_submit.json', 'r') as f:\n",
    "    d2 = json.load(f)\n",
    "    \n",
    "with open('./share/blend.json', 'r') as f:\n",
    "    d1 = json.load(f)\n",
    "    \n",
    "with open('./share/answer_50.json', 'r') as f:\n",
    "    d4 = json.load(f)\n",
    "    \n",
    "with open('./share/rf.json', 'r') as f:\n",
    "    d5 = json.load(f)\n",
    "    \n",
    "with open('./share/2_5312170359494017878.json', 'r') as f:\n",
    "    d3 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_merged = dict()\n",
    "lens = []\n",
    "for user, els1 in d1.items():\n",
    "    merget_score = defaultdict(int)\n",
    "\n",
    "    els2 = d2[user]\n",
    "    els3 = d3[user]\n",
    "    els4 = d4[user]\n",
    "    els5 = d5[user]\n",
    "    union_el = set(els1).union(els2).union(els3).union(els4).union(els5)\n",
    "    for i, el2 in enumerate(els2):\n",
    "        merget_score[el2] += i- 1\n",
    "    for el in union_el.difference(els2):\n",
    "        merget_score[el] += 19\n",
    "        \n",
    "    for i, el3 in enumerate(els3):\n",
    "        merget_score[el3] += i\n",
    "    for el in union_el.difference(els3):\n",
    "        merget_score[el] += 20\n",
    "        \n",
    "    for i, el4 in enumerate(els4):\n",
    "        merget_score[el4] += i+1\n",
    "    for el in union_el.difference(els4):\n",
    "        merget_score[el] += 21\n",
    "        \n",
    "    for i, el5 in enumerate(els5):\n",
    "        merget_score[el5] += i+2\n",
    "    for el in union_el.difference(els5):\n",
    "        merget_score[el] += 22\n",
    "        \n",
    "        \n",
    "    current_top = list(zip(*sorted(merget_score.items(),key=lambda x:x[1])))[0]\n",
    "    lens.append(len(current_top))\n",
    "    sol_merged[user] = current_top[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./share/final.json', 'w') as f:\n",
    "    json.dump(sol_merged, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем map относительно лучшего сабмита\n",
    "def validation(dict_):\n",
    "    d1 = {}\n",
    "    with open('./share/2_5312170359494017878.json', 'r') as f:\n",
    "        d1 = json.load(f)\n",
    "    av = []\n",
    "\n",
    "\n",
    "    for key in d1.keys():\n",
    "        if key in dict_.keys():\n",
    "            ar1 = np.array(d1[str(key)])\n",
    "         # print(ar1)\n",
    "            ar2 = np.array(dict_[str(key)])\n",
    "            inter = np.intersect1d(ar1,ar2)\n",
    "        #  av.append(len(inter))\n",
    "            av.append(mapk([ar1],[ar2]))\n",
    "            to_add = []\n",
    "            for el in ar1:\n",
    "                if el  in inter:\n",
    "                    to_add.append(el)\n",
    "            for el in ar1:\n",
    "                if el  not in to_add:\n",
    "                    to_add.append(el)\n",
    "\n",
    "\n",
    "            to_add = np.array(to_add)\n",
    "    return np.mean(av)\n",
    "\n",
    "\n",
    "\n",
    "def mapk(actual, predicted, k=20):\n",
    "    \n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])\n",
    "  \n",
    "def apk(actual, predicted, k=10):\n",
    "\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    return score / min(len(actual), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5814547965520875"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation(sol_merged)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
